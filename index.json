[{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_assignments/","title":"Assignments","tags":[],"description":"","content":"Here you will find all the assignments for this module.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/00_assignments/","title":"Assignments","tags":[],"description":"","content":"Here you will find all the assignments for this module.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/00_assignments/","title":"Assignments &amp; Exercises","tags":[],"description":"","content":"Here you will find all the assignments for this module.\nIn additional to the real assignments, you will find test exercises for\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/01_networks/0_networks/","title":"Basics Network Analysis","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces unsupervised machine learning (UML)\n Recommended Datacamp exercises:  Python Comming soon R Comming soon    Theory: Network Analysis R Application - Network Analysis Python Application - Network Analysis  Video   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video 1: Intro \u0026 Ecosystem   Video 2: Network Measures/h2   Video 3: Mini-Case/h2      Follow along    Colab Notebook   Video 1: Intro \u0026 Ecosystem   Video 2: Network Measures   Video 3: Mini-Case       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/01_networks/1_networks/","title":"Basics Network Analysis","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces unsupervised machine learning (UML)\n Recommended Datacamp exercises:  Introduction to network Analysis in Python Introduction to network Analysis in R    Theory: Network Analysis R Application - Network Analysis Python Application - Network Analysis  Video   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video 1: Intro \u0026 Ecosystem   Video 2: Network Measures/h2   Video 3: Mini-Case/h2      Follow along    Colab Notebook   Video 1: Intro \u0026 Ecosystem   Video 2: Network Measures   Video 3: Mini-Case       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/02_basics/01_stat_prog/","title":"Basics Statistical Programming","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session is a basic introduction to statistical programming as well as a short brush-up on data more generally. For some, this will be \u0026ldquo;old news\u0026rdquo;, but many will certainly benefit from reviewing this material. We start with a generall theory lecture on data structures and properties, and then dive into R and Python specific applications of statistical programming.\nTheory: Introduction to Data R Application - Statistical Programming Python Application - Statistical Programming  Video   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video      Follow along    Colab Notebook   Video Part 1   Video Part 2   Video Part 3       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/02_cnn_rnn/1_cnn/","title":"Convolutional Neural Networks","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces to convolutional neural networks (CNN) that model spacial dependencies well, and are often used in computer vision.\nSuggested Datacamp courses  Image Processing with Keras in Python  Theory - CNN R Application - CNN Python Application - CNN  Video: Introduction CNNs   Slides Use arrows keys on keyboard to navigate. Fullscreen slides available here     Follow along   Cats and Dogs Detection:  HTML Notebook   Transfer Learning  HTML Notebook   Video 1: CNN No video available, follow the python version, which is pretty much the same workflow.    Follow along   Cats and Dogs Detection  Colab Notebook   Transfer Learning  Colab Notebook   Best practice with Fast.ai  Colab Notebook   Video 1: Cats and Dogs Detection   Video 2: Transfer Learning    Video 3: Best practice with Fast.ai       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/04_workshops/w1/","title":"Day 1","tags":[],"description":"","content":"Practical info Place: DHØ 1.23 Time: 8:15 (we start 15 min later) - 13:20\nSchedule for the day     Time Activity Data     Session 1 8:15-9:45 EDA and DataViz Open Policing   Session 2 10:00-11:30 EDA and UML Digital Nomads   Session 3 12:00-13:20 UML continued. Digital Nomads    Datasets \u0026amp; Context Open policing project The Stanford Open Policing Dataset records trafic stops by US police including data on the vehicle, driver, violation, outcome and many more variables. It has been used in research to investigate racial bias and other issues. I\nDigital Nomad Dataset In this workshop we are going to explore the nomad data using unsupervised ML techniques. This time we will focus on the city data, whichn you have not sen so far.\nWe used the data in a research project some years ago and you can check out a conference presentation below:\n  Suggested Workflow\nYou will find the data for today\u0026rsquo;s session here: https://sds-aau.github.io/SDS-master/M1/data/cities.csv\n Stratup  Load up and explore the data (a bit) Clean up if you thing you neeed to Select the nummerical variables to be used for UML Preprocess the data for UML   Dimensionality reduction  Use PCA for dimensionality reduction Explore variable loading Plot 1. vs 2. component If you want, use another algorithm for the same steps and compare results   Clustering  Perform a clustering on the (reduced?) data Plot the clusters into the above visualization Explore the results (clusters vs components / clusters vs aggregated variables of interest)    "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_workshops/01_workshop1/","title":"Day 1 - Networks","tags":[],"description":"","content":"Practical info Place: DHØ 1.23 Time: 8:15 (we start 15 min later) - 13:20\nSchedule for the day     Time Activity Data     Session 1 8:15-9:00 Intro , Q\u0026amp;A, Introducing dataset Danish power elites   Session 2 9:00-11:30 Network exploration Danish power elites   Session 3 12:00-13:15 WS: AI as a service     Dataset \u0026amp; Context Introduction Context: The Danish Power Elites  Antons PhD Thesis Brief Summary of findings (CBS) Journal Paper in Sociology More to be found with googleling\u0026hellip;  Data  Github (R Repository) Magteliten website Or, easier\u0026hellip; on our github  Tasks  Who are the most central persons? Communities? What characterizes them?   Link up with additional data?    Workshop: AI as a Service By guest: Andreas Markussen\n  Introduction The purpose is to demonstrate a minimum viable product of an ML model deployment. Keeping with the DSBA spirit, I would keep the section hands-on. I would cover a minimal ML pipeline using data that is already preprocessed. The model will be saved to a static file and served through an API. When done, we will have created a web service from scratch, that can be used by any user in their browser. The project will be conducted in Python, with a little HTML added.\nStructure:  Very brief introduction to how the web works - 15 mins Building model and exporting to static file - 15 mins Building Flask web app - 10 mins Adding APIs - 10 mins Adding some HTML and concluding the complete web service - 10 mins Deployment to Heroku free account, short showcase of extensions and other applications (no code here) and rounding off - 15 mins  Preperation To get most of this workshop, you should have:\n Some existing knowledge of Python A local installation of Python Good understanding of an ML flow. No understanding of the web in general  Materials  Data  : Repo  : Slides  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/00_assignments/exercise1/","title":"Exercise 1 - EDA withDigital Nomads","tags":[],"description":"","content":" This is not an assignment, just a voluntary exercise for you to test if you grasp the concepts in the corresponding topics. It does not have to be handed in anywhere\n Data You are given 2 datasets from https://nomadlist.com - A community page for remote workers worldwide. Further, you are provided with a countries list, a dataset containing information on countries, regions and countrycodes.\n Trips data: holds ~46k individual trips of travelers on the platform. https://sds-aau.github.io/SDS-master/M1/data/trips.csv People data: contains some personal information on 4k travelers. https://sds-aau.github.io/SDS-master/M1/data/people.csv Country data: Holds countrycodes, contrynames and region-associations. https://sds-aau.github.io/SDS-master/M1/data/countrylist.csv  Tasks   Preprocessing a. Trips: transform dates into timestamps (note: in Python, you will have to coerce errors for faulty dates) b. Calculate trip duration in days (you can use loops, list comprehensions or map-lambda-functions (python) to create a column that holds the numerical value of the day. You can also use the datetime package.) c. Filter extreme (fake?) observations for durations as well as dates - start and end (trips that last 234565 days / are in the 17th or 23rd century) The minimum duration of a trip is 1 day! Hint: use percentiles/quantiles to set boundaries for extreme values - between 1 and 97, calculate and store the boundaries before subsetting. Rhint: Use percent_rank(as.numeric(variable)) to create percentiles\nd. Join the countrylist data to the trips data-frame using the countrycode as a key e. [Only for python users ] Set DateTime index as the start date of a trip\n  People a. How many people have a least a “High School” diploma? Hint: For this calculation remove missing value-rows or fill with “False”. b. How many “Startup Founders” have attained a “Master’s Degree”? Bonus: compared to people who don’t have a formal higher education (e.g. by using the “False” occurrences)? c. Who is the person with a Master’s Degree that has the highest number of followers? Bonus: Explore the individual further, what else can you find out?\n  Trips a. Which country received the highest number of trips? – And which the lowest? b. Which region received the highest number of trips in 2017? Use the start of trips as a time reference. c. Which country in “Western Europe” did travelers spent least time? – Provide visualization d. Do nomad Startup Founders tend to have shorter or longer trips on average?\n  Solutions  R team :::: HERE :::: Py team (coming\u0026hellip;I know I\u0026rsquo;m late)  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_assignments/exercise1/","title":"Exercise 1 - Network Analysis","tags":[],"description":"","content":"Introduction  In th first Part 2, you will replicate a well known network analysis, with different data and some twists. Data: The data is to be found at: https://github.com/SDS-AAU/SDS-master/tree/master/00_data/network_krackhard (Hint: You neet to download the raw data)  Data: What do I get? Background Let the fun begin. You will analyze network datacollected from the managers of a high-tec company. This dataset, originating from the paper below, is widely used in research on organizational networks. Time to give it a shot as well. Krackhardt D. (1987). Cognitive social structures. Social Networks, 9, 104-134. The company manufactured high-tech equipment on the west coast of the United States and had just over 100 employees with 21 managers. Each manager was asked to whom do you go to for advice and who is your friend, to whom do you report was taken from company documents. Description\nThe dataset includes 4 files - 3xKrack-High-Tec and 1x High-Tec-Attributes. Krack-High-Tec includes the following three 21x3 text matrices:\n ADVICE, directed, binary FRIENDSHIP, directed, binary REPORTS_TO, directed, binary  Column 1 contains the ID of the ego (from where the edge starts), and column 2 the alter (to which the edge goes). Column 3 indicates the presence (=1) or absence (=0) of an edge.\nHigh-Tec-Attributes includes one 21x4 valued matrix.\n ID: Numeric ID of the manager AGE: The managers age (in years) TENURE: The length of service or tenure (in years) LEVEL: The level in the corporate hierarchy (coded 1,2 and 3; 1 = CEO, 2 = Vice President, 3 = manager) DEPT: The department (coded 1,2,3,4 with the CEO in department 0, ie not in a department)  Tasks 1. Create a network  Generate network objects for the companies organizational structure (reports to), friendship, advice This networks are generated from the corresponding edgelists Also attach node characteristics from the corresponding nodelist  2. Analysis Make a little analysis on:\nA: Network level characteristics. Find the overal network level of:\n Density Transistivity (Clustering Coefficient) Reciprocity  \u0026hellip; for the different networks. Describe and interpret the results. Answer the following questions:\n Are relationships like friendship and advice giving usually reciprocal? Are friends of your friends also your friends? Are the employees generally more likely to be in a friendship or advice-seeking relationship?  B: Node level characteristics: Likewise, find out:\n Who is most popular in the networks. Who is the most wanted friend, and advice giver? Are managers in higher hirarchy more popular as friend, and advice giver?  C: Relational Characteristics: Answer the following questions:\n Are managers from the same 1. department, or on the same 2. hirarchy, 3. age, or 4. tenuere more likely to become friends or give advice? (hint: assortiativity related) Are friends more likely to give each others advice?  3. Visualization Everything goes. Show us some pretty and informative plots. Choose what to plot, and how, on your own. Interpret the results and share some insights.\nSubmission as PDF (notebook and output)\n  "},{"uri":"https://sds-aau.github.io/DSBA-2021/info/","title":"Info, Schedule &amp; Co","tags":[],"description":"","content":"General info about the semester are to be found here, including topics, schedule, and infrastructure. Here, we also point towards additional resources to acquire and apply your data science skills.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/info/01_infrastructure/","title":"Infrastructure","tags":[],"description":"","content":"Main Infrastructure  MS teams : Join our MS our teams channel to get updates from us, Q\u0026amp;A, and talk to your peers. Canvas : We will not use it from now on for content, but for the sake of completeness. However, you will still find your calendar there and we may use it from time to time to send out mass-mails to you all. Datacamp : Get access to all the Datacamp premium content for free to facilitate your data science journey. Use your CBS mail here when signing up.  Adittional Infrastructure used  Github Provides internet hosting for software development and version control using Git. It offers the distributed version control and source code management (SCM) functionality of Git, plus its own features. It is also commonly used to host open-source projects, including data science projects. If you do not have it already, you are advice to create an account to manage and showcase your work during this semester. A brief introduction into the main functionalists can be found here.  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/01_ann/1_ann/","title":"Introduction Neural Networks","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces to artificial neural networks (ANN) and Deep Learning (DL)\nSuggested Datacamp courses  Introduction to TensorFlow in R Introduction to Deep Learning in Python  Theory: Neural Networks and Deep Learning R Application - Neural Networks Python Application - Neural Networks  Video 1: Introduction and history of ANNs   Video 2: Building blocks and architecture of ANNs   Video 3: Learning in ANNs   Slides Use arrows keys on keyboard to navigate.   Fullscreen slides available here   Fullscreen slides available here   Follow along    HTML Notebook   Video 1: Images and Penguins   Video 2: Details and Tabular Data Example      Follow along    Colab Notebook   Video 1: Penguin Multiclass prediction       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/02_nlp/0_nlp_theory/","title":"Natural Language Processing - Theory","tags":[],"description":"","content":"In this part you\u0026rsquo;ll get a 100% code-free intro to (statistical) Natural Language Processing\n Recommended Datacamp exercises:  Python Intro to NLP Python - also good Feature Engineering for NLP in Python R Introduction to Natural Language Processing in R    NLP intro - level of analysis Text representation From BoW to Topic Modeling and Embeddings (optional) History of NLP in Industry - Yoav Goldberg                "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/03_ml/01_uml/","title":"Unsupervised Machine Learning (UML)","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces unsupervised machine learning (UML)\n Recommended Datacamp exercises:  Python R    Theory: Unsupervised ML R Application - UML Python Application - UML  Video   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video 1: EDA \u0026 Dimensionality Reduction   Video 2: Clustering      Follow along    Colab Notebook   Video 1: EDA \u0026 Dimensionality Reduction   Video 2: EDA \u0026 Clustering       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/02_nlp/1_nlp_string/","title":"Application: String Manipulation","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n R Application - String Manipulation Python Application - String Manipulation   Follow along    HTML Notebook   Video      Follow along    Colab Notebook   Video 1   Video 2       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/","title":"Applied Data Science and Machine Learning","tags":[],"description":"","content":"M1 - Applied Data Science and Machine Learning This module provides a condensed introduction to the “Data Science Pipeline”, introducing students to methods, techniques, and workflows in applied data analytics and machine learning, including data acquisition, preparation, analysis, visualization, and communication.\nContent by week for this module Click on the to do for the week to see what you should do to keep up with the module.\n   W 36: Data Manipulation, Exploratory Data Analysis (EDA), Data Visualization   Weekly to do    Introduction to R \u0026amp; Python (Datacamp, both necessary if no prior experience)  Intro to Python and/or R [Intro to R   Statistics Refresher (Datacamp, recommended if no prior statistics classes, choose either R or Python)  Python  Statistical Thinking 1 Statistical Thinking 2 Intro to linear modelling   R:  Introduction to data in R Foundation of probability; Correlation and regression     Course Material (Watch videos, study/run notebooks, solve provided exercises, optimally study suggested further material)  Warmup Basics Data Manipulation     \n  W 37: Unsupervised Machine Learning (UML), Supervised Machine Learning (SML)   Weekly to do    Continue with the Course material (Datacamp, recommended but not mandatory)  Python  UML Intro to supervised learning Decision Tree modeling   R  UML Supervised classification Supervised Regression     Course Material (Watch videos, study/run notebooks, solve provided exercises, optimally study suggested further material)  Unsupervised ML Supervised ML   Prepare for Q\u0026amp;A (discuss in teams, send/prepare questions)   \n  W 38: Workshop \u0026amp; project work\n  Q\u0026amp;A Sessions W36   W37   "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/02_basics/02_data_manipulation/","title":"Basics Data Manipulation","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces some fundamental concepts of data manipulation and Exploratory Data Analysis. We will again start with a theoretical lecture on fundamental concepts and techniques in data manipulation, and afterwards again explore them in R and Python specific applications. These applications are complemented by recap exercises to test yourself.\nTheory: Fundamentals of Data Manipulation R Application - Data Manipulation Python Application - Data Manipulation  Video   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Complementary Exercises    1 Basics    2 Joins    3 Challange   Video      Follow along    Colab Notebook   Video       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/02_basics/","title":"Basics of Statistical Programming and Data Manipulation (W36)","tags":[],"description":"","content":"This chapter is a basic introduction to statistical programming as well as a short brush-up on data more generally. For some, this will be \u0026ldquo;old news\u0026rdquo;, but many will certainly benefit from reviewing this material. Afterwards, we introduces some fundamental concepts of data manipulation and exploratory data analysis (EDA).\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/04_workshops/w2/","title":"Day 2","tags":[],"description":"","content":"Practical info Place: K 143 Time: 11:40 - 17:00\nSchedule for the day     Time Activity Data     Session 1 11:40-13:00 SML - Regression AirBnb   Session 2 13:20-14:50 SML - Regression and intro classification AirBnb   Session 3 15:00-16:30 SML - Classification HR data - Updated Description   Session 4 16:40-17:00 Wrapup, Assignment handout -    "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_workshops/02_workshop2/","title":"Day 2 - Classification of Political US Tweets","tags":[],"description":"","content":"Introduction Context: Presidential Debate 2020 Yes, we are going back in time to the Presidential Debate in the US 2020 - the time of lots of unhappy Tweeting. It\u0026rsquo;s just too good a dataset and case to let it go\u0026hellip;\nData   Political tweets: https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/pol_tweets.gz from https://github.com/alexlitel/congresstweets We\u0026rsquo;ve preprocessed a bit to make things easier. 1: Dems. 0: Rep.\n  Tweets around the time of the debate in oktober 20 (8000): https://github.com/SDS-AAU/SDS-master/raw/master/M2/data/pres_debate_2020.gz\n  Both datasets are in JSON format.\nTasks  Preprocess both datasets for NLP (supervised) Start by building a classification model for the congress tweets Use a well performing model to classify new data (tweets from the presidential debate) Explore the different classes  Schedule for the workshop    Time Activity     11:40-12:00 Introduction to the context   12:00-13:00 Joint EDA and NLP refresher   13:15-14:45 Setting up the NLP workflow on congress tweets   15:00-16:00 PRedicting on new data, evaluation of results   16:15-17:00 Hand out Peergrade assignment, Introduction to final project    "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/00_assignments/exercise2/","title":"Exercise 2 - UML with Pokemon","tags":[],"description":"","content":" This is not an assignment, just a voluntary exercise for you to test if you grasp the concepts in the corresponding topics. It does not have to be handed in anywhere\n Description This time you will work with Pokemon data. No data munging needed. Just old-school (U)ML.\nData The data is available through the URL: https://sds-aau.github.io/SDS-master/00_data/pokemon.csv. It contains data on 800 Pokemon from the 1st to the 6th generation.\nTasks  Give a brief overview of data, what variables are there, how are the variables scaled and variation of the data columns. Execute a PCA analysis on all numerical variables in the dataset. Hint: Don\u0026rsquo;t forget to scale them first. Use 4 components. What is the cumulative explained variance ratio? Hint: I am not sure this terminology and code was introduced during class, but try and look into cumulative explained variance and sklearn(package) and see if you can figure out the code needed. Use a different dimensionality reduction method (eg. UMAP/NMF) – do the findings differ? Perform a cluster analysis (KMeans) on all numerical variables (scaled \u0026amp; before PCA). Pick a realistic number of clusters (up to you where the large clusters remain mostly stable). Visualize the first 2 principal components and color the datapoints by cluster. Inspect the distribution of the variable Type1 across clusters. Does the algorithm separate the different types of pokemon? Perform a cluster analysis on all numerical variables scaled and AFTER dimensionality reduction and visualize the first 2 principal components. Again, inspect the distribution of the variable “Type 1” across clusters, does it differ from the distribution before dimensionality reduction?  Solutions  R team :::: HERE :::: Py team :::: HERE :::: - Includes also some SML  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_assignments/exercise2/","title":"Exercise t 2 - NLP","tags":[],"description":"","content":"Introduction: Building a Hate Speech Classifier This assignment is less structured than previous individual assignments.\nYou are given a collection of approximately 25k tweets that have been manually (human) annotated. class denotes: 0 - hate speech, 1 - offensive language, 2 - neither\nhttps://github.com/SDS-AAU/SDS-master/raw/master/M2/data/twitter_hate.zip\n1. Preprocessing and vectorizaion. Justify your choices and explain possible alternatives (e.g. removing stopwords, identifying bi/tri-grams, removing verbs or use of stemming, lemmatization etc.)\n Create a bag-of-words representation, apply TF-IDF and dimensionality reduction (LSA-topic modelling alternatively simply PCA or SVD) to transform your corpus into a feature matrix.  2. Explore and compare the 2 \u0026ldquo;classes of interest\u0026rdquo; - hate speech vs offensive language.  Can you see differences by using simple count-based approaches? Can you identify themes (aka clusters / topics) that are specific for one class or another? Explore them using, e.g. simple crosstabs - topic vs. class and to get more detailed insights within-cluster top (TF-IDF) terms. (This step requires preprocessed/tokenized inputs).  3. Build an ML model that can predict hate speech Use the ML pipeline (learned in M1) to build a classification model that can identify offensive language and hate speech. It is not an easy task to get good results. Experiment with different models on the two types of text-representations that you create in 2.\nBonus: Explore missclassified hate speech tweets vs those correctly predicted. Can you find specific patterns? Can you observe some topics that are more prevalent in those that the model identifies correcly?\nThe best-reported results for this dataset are.\n   Class Precision     0 0.61   1 0.91   2 0.95   Overall 0.91    Here advanced NLP feature engineering has been used, and thus everything around an overall accuracy of 85 is fine. You will see that it is not easy to lift class 0 accuracy over 0.5\nGood Luck!\nSubmission as PDF (notebook and output)\n  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/01_networks/2_networks_intermediate/","title":"Intermediate Network Analysis","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces to slightly more advanced concepts in network analysis\nR Application - Intermediate Network Analysis Python Application - Intermediate Network Analysis   Follow along    HTML Notebook  Notebook    Colab Notebook   Video 1      Follow along    Colab Notebook   Video 1: Intro    Video 2: Case       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/01_warmup/01_business/","title":"Intro Talk - Data Science in business","tags":[],"description":"","content":" Use the tabs to access content\n This Video series contains a 3-part talk by Daniel and Roman on data science applications in business\nFollow along:\n  Slides DS in business  1 - Current state 2 - Intro ML 3 - DS Teams   Data Science in business 1 - Current state      Data Science in business 2 - Introduction to Machine Learning      Data Science in business 3 -Team and Roles       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/02_cnn_rnn/2_rnn/","title":"Recurrent Neural Networks","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces to recurrent neural networks (RNN) and Long-Short-Term Memory Networks (LSTM), which model sequential data well (eg. text, timeseries)\nSuggested Datacamp courses  Recurrent Neural Networks for Language Modeling in Python  Theory - Recurrent Neural Networks R Application - RNN Python Application - RNN  Video: Introduction CNNs   Slides Use arrows keys on keyboard to navigate. Fullscreen slides available here     Also check Python MAterial  Follow along    HTML Notebook   Video 1: Intro RNN   Video 2: IMDB Case       Follow along   Simple Timeseries  Colab Notebook   Bi-LSTM on IMDB  Colab Notebook   Video 1: Simple Timeseries   Video 2: Bi-LSTM on IMDB        "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/03_ml/02_sml/","title":"Supervised Machine Learning (SML)","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces unsupervised machine learning (UML)\n Recommended Datacamp exercises:  Python - Intro to supervised learning Python - Decision Tree modeling R - Supervised classification R - Supervised Regression    Theory: Supervised ML R Application - SML Python Application - SML  Video 1: Introduction \u0026 Statistics Refresher   Video 2: Generalization, Model Classes \u0026 Tuning   Slides Use arrows keys on keyboard to navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video 1: Introduction \u0026 ML workflows with tidymodels   Video 2: Regression problem case   Video 3: Classification problem case      Follow along    Colab Notebook   Video 1: Introduction \u0026 ML/Model fitting Mechanics    Video 2: Regression problem case    Video 3: Classification problem case and more        "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/00_assignments/01_exercise1/","title":"Workshop 1 - AirBnb revisited","tags":[],"description":"","content":"Introduction Context: Flashback to AirBnb Data that we used in Workshop 3 of M1 In this workshop we are going to explore the insideairbnb using deep learning techniques. We used the data in a research project some years ago and you can check out a conference presentation below:\n1. Build a neural net for price prediction. Your job is to build a feed-forward network using Keras to predict the price. Can you beat the performance of other models that we explored in M1 (using the same set of independent variables)? Start with a \u0026ldquo;simpler\u0026rdquo; baseline model using 1 2 layers only (one input layer one output layer).\n2. Tune the network. Experiment with different set-ups changing e.g.:\n number of neurons number of layers number of epochs and batch size activation functions (reasonable choices) optimizers and losses (again: reasonable choices)  Use the Keras documentation and community sources to identify best practices. However, do not spend hours on grid search!\n3. Prevent overfitting This part is related to 2. Explore the training process (over the epochs). Explore and describe 2 common approaches used to prevent overfitting in deep feed-forward neural nets.\nIn class Notebooks  R team :::: HERE ::::  Py Team  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_workshops/","title":"Workshops","tags":[],"description":"","content":"In the live workshops we will aim at working with real world data in groups in class. Towards the end of the session, we will be collecting and disckussin results.\nIn class Recordings and Notebooks Day 1  Elites  R code-along Python Notebook      US presidential tweets  R code-along Python Notebook    Part 1 (before lunch)  \nPart 2 (after lunch)  \n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/02_nlp/2_nlp_longtext/","title":"Application: Working with long text","tags":[],"description":"","content":"Working with long text and extracting text elements Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n R Application - Working with long text Python Application - Working with long text   Follow along    HTML Notebook   Preprocessing \u0026 Sentiments      Follow along    Colab Notebook   can be watched at 1.5x 😉 Link to News-scraping tutorial in the notebook.       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/02_basics/03_data_visualization/","title":"Basics Data Visualization","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces some fundamental concepts of data visualization. After a theoretical lecture on types and dimensions of data visualization, we will explore the visualization of different data types, structure, and properties in R and Python specific applications.\nTheory: Elements of Data Visualization R Application - Data Visualization Python Application - Data Visualization  Video   Slides Use arrows keys on keyboardto navigate. Alternatively fullscreen slides available here     Follow along    HTML Notebook    Colab Notebook   Video      Follow along    Colab Notebook   Video Part 1   Video Part 2       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/01_ann/","title":"Introduction to Neural Networks","tags":[],"description":"","content":"This chapter introduces you to artificial neural networks (ANN) and deep learning (DL)\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/info/02_modules/","title":"Modules","tags":[],"description":"","content":"The course is structured in 3 modules.\nM1: Applied Data Science and Machine Learning This module will prove a condensed introduction to the “Data Science Pipeline”, introducing students to methods, techniques, and workflows in applied data analytics and machine learning, including data acquisition, preparation, analysis, visualization, and communication.\nM2: Network Analysis and Natural Language Processing Focuses on analyzing a variety of unstructured data sources. Particularly, students will learn how to explore, analyze, and visualize natural language (text) as well as relational (network) data.\nM3: Deep Learning and Artificial Intelligence for Analytics Introduces to the most recent developments in machine learning, which are deep learning and artificial intelligence applications. The module will provide a solid foundation for this exciting and rapidly developing field. Students will learn whether and how to apply deep learning techniques for business analytics, and acquire proficiency in new methods autonomously.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/01_networks/3_networks_2mode/","title":"Network 2-Mode","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n This session introduces to multimodel natwork analysis concepts\nR Application -2-mode Network Analysis Python Application - -2-mode Network Analysis   Follow along    HTML Notebook  Notebook    Colab Notebook  Video 1: Intro   Video 2: Application      Follow along    Colab Notebook 1/a    Colab Notebook 2   Video 1: Intro    Video 2: Case       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/01_networks/","title":"Network Analysis","tags":[],"description":"","content":"This chapter introduces you to network analysis and working with relational data.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/","title":"Network Analysis &amp; NLP","tags":[],"description":"","content":"M2 - Network Analysis \u0026amp; NLP This module provides a condensed introduction analysing two popular forms of unstructured data, namely relational and text data.\nContent by week for this module Click on the to do for the week to see what you should do to keep up with the module\n  W 40: Introduction to Network Analysis W 41: Introduction to Natural-Language-Processing (NLP) W 41: Advanced applications in Network and Text Analysis W 42: Assignment work  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/02_cnn_rnn/","title":"Advanced architectures","tags":[],"description":"","content":"This chapter introduces you to neural network architectures going beyond feed-forward neural networks. We will particularly focus on convolutional neural networks that model spatial dependencies (eg. in computer vision) and recurrent neural networks that model sequential data (eg. text and time series)\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/02_nlp/3_nlp_topic/","title":"Application: Vectorization and Topic Modelling","tags":[],"description":"","content":" Use the tabs to access content. Theory part is general, R \u0026amp; Python application part language specific.\n R Application Python Application   Follow along    HTML Notebook        Follow along    Colab Notebook   Video Ecosystem   Video Tutorial       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/03_ml/","title":"Basics Machine Learning (W37-38)","tags":[],"description":"","content":"This chapter introduces you to the intuition behind unsupervised (UML) and supervised machine (SML) learning, and demonstrates common techniques and workflows. It contrasts UML (=trained on labeled data) with SML (trained on labeled data), and also distinguishes it from traditional inferential statistics (e.g. econometrics).\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/m3/","title":"Deep Learning","tags":[],"description":"","content":"M3 - Deep Learning Introduces to the most recent developments in machine learning, which are deep learning and artificial intelligence applications. The module will provide a solid foundation for this exciting and rapidly developing field. Students will learn whether and how to apply deep learning techniques for business analytics, and acquire proficiency in new methods autonomously.\nContent by week for this module Click on the to do for the week to see what you should do to keep up with the module\n  W 43: Introduction to Artificial Neural Networks (ANN) \u0026amp; Deep Learning (DL) W 44: Neural networks for spatial data: Recurrent Neural Networks (RNN) W 45: Neural Networks for sequential data: Recurrent Neural networks (RNN \u0026amp; LSTM) W 46: Workshop: Advanced DL applications  Preperation Datacamp:  Introduction to TensorFlow in R Introduction to Deep Learning in Python Image Processing with Keras in Python Recurrent Neural Networks for Language Modeling in Python Advanced Deep Learning with Keras  Additional:  3Blue1Brown Visual Introduction to Neural networks SOTA Language Processing Keras R-Keras RStudio AI blog: Excellent source for frequent torch/keras exercises and announcements within th R ecosystem fast.ai Machinelearningmastery  "},{"uri":"https://sds-aau.github.io/DSBA-2021/info/04_litetrature/","title":"Literature &amp; Resources","tags":[],"description":"","content":"While this course does not come with a list of mandatory readings, we will often refer to some central resources in R and python, which for the most part can always be accessed in a free and updated online version. We generally recommend you to use these amazing resources for problem-solving and further self-study on the topic.\nMain Literature These pieces of work can be seen as main references for data science using R and Python. We will frequently refer to selected chapters for further study.\nR  Wickham, H., \u0026amp; Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data. O\u0026rsquo;Reilly Media, Inc. Online available here Baumer, B., Kaplan, D. \u0026amp; Horton, N. (2020) Modern Data Science with R (2nd Ed.). CRC Press Online available here Kuhn, M., Silge, J. (2020) Tidy Modeling with R Online available here  Python  VanderPlas, J. (2016). Python data science handbook: Essential tools for working with data. O\u0026rsquo;Reilly Media, Inc. Online available here  Supplementary literature R  R Markdown: The Definitive Guide Efficient R Programming Functional Programming in R (Stanford, Hadley) Exploring Enterprise Databases with R  Further Ressources Data Science Cloud services  Notebook bases:  Google Colab: Googles popular service for editing, running \u0026amp; sharing Jupyter notebooks (Only Python Kernel, but R kernel can be accessed via some tricks) Deepnote: New popular online notebook service with good integration to other services (Python, R \u0026amp; more) Kaggle: Also provides their own cloud-based service co create and run computational notebooks. Convenient, unlimited, but a bit slow (Pyhton, R ).    Community  Kaggle: Crowdsourced data science challanges. Nowadays also provides a vivid community where you find datasets, notebooks for all kind of data science exercises.  Tools \u0026amp; Helpers  rmd to ipynb converter ipynb to pdf converter  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/00_assignments/group_assignment/","title":"M1 (Mandatory) Assignment","tags":[],"description":"","content":"DSBA 2021 - M1: (Mandatory) Assignment Introduction With the individual assignments, you already performed most of the steps in a typical machine learning pipeline. You imported some data, cleaned it, explored the variables and their relationships using summary statistics and visualisations. You also exercised some standard machine learning preprocessing procedures such as feature scaling and dealing with missing values.\nYou practised unsupervised machine learning techniques for dimensionality reduction (e.g. PCA) and clustering (e.g. KNN) to discover latent relationships between features and groupings of observations. In the final workshop and online material you finally used supervised machine learning for regression and classification problems, where you created models to predict an outcome of interest given some input features.\nNow it is time to bring most these steps together and apply them to a setting that you find interesting. This should apply the following tasks.\n Identify an interesting problem that can be tackled using data science techniques. Select and obtain relevant data to do so. Clean and manipulate the data to make it useful for data science techniques. Carry out an exploratory data analysis to provide intuition into the content of the data, and interesting relationships to be found in it. You might unsupervised ML techniques to discover latent relationships within the data. Use supervised ML techniques to create models that predict an outcome of interest. Document your workflow in a reconstructable manner. Report your findings in an accessible manner.  Task description Data \u0026amp; Problem identification In this exercise, you are asked to choose and obtain a dataset you consider interesting and appropriate for the tasks required. Some of you may already have some ideas about interesting datasets. There are many open datasets available on the internet (e.g. kaggle or individual projects like Stanford Open Policing or download some of the Datacamp project datasets) here a recent list of open data repositories for inspiration\nIf you instead want to collect your data (e.g. scraping Twitter or other platforms) – we will not hold you back. However, consider the timeframe.\nThe data should fulfill the following minimum requirements:\n It should be big enough to be useful for applying data science techniques (rule of thumb: minimum \u0026gt; 500 observations, \u0026gt; 10 features). It contains an interesting outcome to be predicted via supervised ML. It is not completely trivial and clean, and at least requires a minimum amount of cleaning, munging, preprocessing (eg. no toy dataset such as Iris, diamonds, or cars).  Analysis pipeline The analysis to be carried out by you has to contain elements of data manipulation, exploration, unsupervised and supervised ML.\nGenerally, you can combine parts from the individual assignments and use them as a template for the module assignment. Going beyond that is not required (but for sure appreciated). Below a (rather detailed) checklist to make sure you have all the pieces.\n Definition of a problem statement and a short outline of the implementation Description of data acquisition / how it was collected (by you or the publisher of the data) Data preparation  Data cleaning (if needed) Recoding (label encoding, dummy creation etc.) Merging and wrangling (if needed)   Exploratory data analysis  Relevant! summary statistics Relevant! visualisations Appropriate description (This is important!) Optional! unsupervised machine learning for EDA or SML preprocessing (eg. dimensionality reduction, clustering)   Feature scaling (if applicable) Missing data handing (dropping or inputing) Supervised ML  Train- / Testset preparation classification or/and regression problem Use of different algorithms (min. 3) compared and ranked according to their performance using appropriate metrics (k-fold cross-validation) you may include hyperparameter tuning (grid-search, adaptive resampling etc.) performance evaluation on the test set (scores, performance reports but also visuals where useful)    Many of the steps are optional. So choose which methods you deem helpful and relevant to explore your chosen problem.\nNote: Quality \u0026gt; Quantity. Consider which analysis, summarization, and visualization adds value. Excessive and unselective outputs (e.g. running 20 different models without providing a reason for, providing all possibilities of different plots without discussing and evaluating the insights gained from it) will not be considered helpful but rather distracting.\nDocumentation and Deliverables You are asked to hand in a well commented functional computational notebook\nComputational Notebook The notebook targets a machine-learning literate audience. Here you can go deeper into the technical details and method considerations. Provide thorough documentation of the whole process, the used methods. Describe the intuition behind the selected and used methods, justify choices made, and interpret results (e.g. Why scaling? Why splitting the data? Why certain tabulations and visualizations? What can be seen from \u0026hellip; ?, How did you select a particular algorithm? Why did you scale features in one way or another?).\nPlease provide the notebook as a PDF.\nFinally  Submission deadline is 29.09, 23:59 - on peergrade (class code: N8A46K) Peer Feedback deadline is 04.10, 23:59 - PRovide constructive comments as you would like to recieve them In case of trouble/issues/questions, please write on Teams.  Getting good looking PDFs from jupyter notebooks   "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/04_workshops/","title":"M1 Workshops","tags":[],"description":"","content":"Our first round of live workshops. For details, see the individual days.\nNotebooks Day 1  Open Policing EDA  R code-along Python Notebook - EDA   Digital Nomads UML  R code-along Python Notebook - UML    Day 2  InsideAirBnB SML  python notebook working edition R code-along    "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/00_assignments/group_assignment/","title":"M2 (Mandatory) Assignment","tags":[],"description":"","content":"DSBA 2021 - M2: (Mandatory) Assignment Introduction Now it is time to bring most these steps together and apply them to a setting that you find interesting. This should apply the following tasks.\n Identify an interesting problem that can be tackled using netork analysis and NLP techniques. Optimally, this is done within one dataset. However, the assignment can also be done using 2 different datasets, if nothing suitable combinging both elements of netork analysis and NLP is found. Select and obtain relevant data to do so. Clean and manipulate the data to make it useful for network analysis and NLP techniques. Execute an analysis containing elements of network analysis and NLP you have been exposed to (\u0026hellip; or beyond) Document your workflow in a reconstructable manner. Report your findings in an accessible manner.  Task description You have the choice between two different assignments:\n Find and select datasets on your own, and perform an interesting and informative analysis using the elements stated above on your own. Solve both exercise 1 and 2 separately, using the corresponding dataset and following the stated tasks accordingly.  Data \u0026amp; Problem identification (for option 1.) NOTE: Follow this if you choose option 1 and ant to work with own data. Otherwise, follow the tasks of M2 exercise 1 and 2\nIn this exercise, you are asked to choose and obtain a dataset you consider interesting and appropriate for the tasks required. You are welcome to use existing datasets for language and networks but at this stage you could also consider getting your own data (e.g. Twitter API, Instagram, news repositories etc.)\nThe data should be large enough and of proper granularity to be interesting for NLP and network analysis techniques. If you are in doubt, please reach out.\nWhat we expect you to do:\n Identify an interesting problem that can be tackled using data science techniques applied to natural language and networks. Select and obtain relevant data to do so. Clean and manipulate the data to make it useful. Carry out an exploratory data analysis to provide intuition into the content of the data, and interesting relationships to be found in it. Use unsupervised ML techniques to discover relationships within the data such as interesting topics or latent network structures. Use supervised ML techniques to create models that predict an outcome of interest. Document your workflow in a reconstructable manner. Report your findings in an accessible manner.  Analysis pipeline The analysis to be carried out by you has to contain elements of data manipulation, exploration, unsupervised and supervised ML as applied to relational and language data.\nIn the best case, you combine network data with language elements. Twitter is a good (and easy) example, as you can, for instance, combine mention-networks with sentiments expressed in the tweets. The article below is a creative example of that (with a rather small NLP part).\nLiu, Z., \u0026amp;amp; Weber, I. (2014, November). Is Twitter a public sphere for online conflicts? A cross-ideological and cross-hierarchical look. In International Conference on Social Informatics (pp. 336-347). Springer, Cham.\n Definition of a problem statement and a short outline of the implementation Description of data acquisition / how it was collected (by you or the publisher of the data) Data preparation (general)  Data cleaning (if needed) Recoding (label encoding, dummy creation etc.) Merging and wrangling (if needed)   Missing data imputation (if applicable and deemed relevant) Network Data - preparation  Extraction and formatting Creation of functional graphs with relevant attributes   NLP - preparation  Extraction \u0026amp; Cleaning Tokenization Filtering \u0026amp; Lemmatization / Stemming (if needed)   Network analysis  Calculation of relevant indicators on different levels / EDA Projection (in the case of bipartite graphs) Identification of community structures   NLP  EDA / simple frequency-based analysis Simple vectorization (BoW, Tf-idf) Topic modelling / Clustering (LDA / LSA) Embedding-model based vectorization (Word2Vec, Fasttext, GloVe)   Supervised / Unsupervised ML  Try to link your results from network analysis or NLP with a more traditional ML problem.    Many of the steps are optional. So choose which methods you deem helpful and relevant to explore your chosen problem.\nNote: Quality \u0026gt; Quantity. Consider which analysis, summarization, and visualization adds value. Excessive and unselective outputs (e.g. running 20 different models without providing a reason for, providing all possibilities of different plots without discussing and evaluating the insights gained from it) will not be considered helpful but rather distracting.\nSome inspirational examples (non-binding, and non-exhaustive):  You obtain a dataset with tweets on a current debate (e.g. #MeeToo) and try to map the discourse.  You perform “naive” NLP, counting handles, hashtags, basic plotting etc. to get some overview. You perform “out-of-the-box” sentiment analysis and plot tweets on a map, colouring by sentiment. You perform topic modelling and identify the sub-discussions. Isolating handles/retweets, you identify some interaction patterns, use network indicator to identify thought leaders or conflicting communities as well as people that try to negotiate between positions.   You obtain a bibliographic dataset on a field of study (or from an entity such as a university) of interest, e.g., from scopus.  You perform a network analysis on different levels of aggregations, identifying key publications, scientists etc. You run a topic model to identify relevant discourses. You might then answer questions such as: Did the discourses change over time? In case so, who or what drives these changes?    Documentation and Deliverables You are asked to hand in a well commented functional computational notebook\nComputational Notebook The notebook targets a machine-learning literate audience. Here you can go deeper into the technical details and method considerations. Provide thorough documentation of the whole process, the used methods. Describe the intuition behind the selected and used methods, justify choices made, and interpret results.\nPlease provide the notebook as a PDF.\nFinally  Submission deadline is 20.10, 23:59 - on peergrade (class code: N8A46K) Peer Feedback deadline is 25.10, 23:59 - Provide constructive comments as you would like to recieve them In case of trouble/issues/questions, please write on Teams.  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m2/02_nlp/","title":"Natural Language Processing","tags":[],"description":"","content":"This chapter introduces you to Natural Language Processing and how you can work with text data in machine learning pipelines.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/info/03_schedule/","title":"Semester Schedule","tags":[],"description":"","content":"M1: Week 36-38 Topics  W 36: Data Manipulation, Exploratory Data Analysis (EDA), Data Visualization W 37: Unsupervised Machine Learning (UML), Supervised Machine Learning (SML) W 38: Workshop \u0026amp; project work  M2: Week 39-41 Topics  W 39: Introduction to Network Analysis W 40: Introduction to Natural-Language-Processing (NLP) W 41: Workshop \u0026amp; project work  M3: Week 43-46 Topics  W 43: Introduction to Artificial Neural Networks (ANN) \u0026amp; Deep Learning (DL) W 44: Neural networks for spatial data: Recurrent Neural Networks (RNN) W 45: Neural Networks for sequential data: Recurrent Neural networks (RNN \u0026amp; LSTM) W 46: Workshop \u0026amp; project work  Key Dates   In-person workshops on CBS campus (always Thursday + Friday)\n 1: W38: Machine learning case studies 2: W41: Advanced applications in Network and Text Analysis 3: W46: Advanced applications \u0026amp; outlook in deep learning    Individual assignment (2 out of 3 need to be passed):\n 1: 24.-29.09.2021, 23:59:00 at the latest (Peergrade) 2: 15.-20.10.2021, 23:59:00 at the latest (Peergrade) 3: 19.-24.09.2021, 23:59:00 at the latest (Peergrade)    Final exam: 15.12.2021\n  "},{"uri":"https://sds-aau.github.io/DSBA-2021/info/05_requirements_project/","title":"Semester Project Requirements","tags":[],"description":"","content":"Format  Functional and self-contained notebook Happy to see GitHub repos (which you can use as your portfolio in the job market) Project report (30-ish pages - max. 45\u0026hellip; depending on group size) Some study relation (but that is debatable and not necessarily required) Report is a (semi/non) technical documentation. Think about a corporate censor that you try to inform  Content  Problem formulation with some practical and theoretical motivation (no huge literature discussion) Methodology (not a critical realist vs positivist discussion but some ideas about what can be concluded potentially) Data sourcing and pre-processing strategy Overall architecture of the model(s) Modelling (incl. finetuning) Results Discussion / Conclusion  Scope  Uses different methods from the course (at least 2 modules) in a creative way Downloading data from kaggle/github and running an ML model is probably not enough for a good performance Creative combinations of methodologies, please:  combine financial data with social media data to look at equity development extract information from text data and create networks. Use network indicators to supplement company data   Evaluation will focus on correct application and communication of DS methods The level of \u0026ldquo;technicality\u0026rdquo; is as in the course with emphasis on application and intuition, not on ML engineering / mathematics However, you will need to demonstrate insight into statistics on a level that is required to discuss your assignment e.g. interpret and discuss performance indicators, outline strategies for improvement e.g. under/oversampling  "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/01_warmup/02_ecosystem/","title":"The Data Science Ecosystem","tags":[],"description":"","content":" Use the tabs to access content\n This Video series contains an introduction to the data science ecosystem, includng a general as well as a R and Python specific overview.\nR Ecosystem Python Ecosystem DS Ecosystem general  Video   Slides     Video   Slides      Video   Slides       "},{"uri":"https://sds-aau.github.io/DSBA-2021/m1/01_warmup/","title":"Warmup (W36)","tags":[],"description":"","content":"This warmup introduces on a high level to the use of DS/ML methods in Business. The second part of the warmup provides an overview of the infrastructure used at DSBA.\nData Science in Business In this chapter you learn about data science and ML applications in business applications. The presentations have been recorded as part of a workshop on Data Science for Business Leaders. Contents are not part of the course curriculum, yet a good way to get more familiar with terminology.\nIntroduction to the Data Science Ecosystem Overview of software, platforms and most other things you are going to work with at DSBA. You only have to work in one of the 2 languages but it\u0026rsquo;s still nice to know how the other ecosystem looks like\u0026hellip;\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://sds-aau.github.io/DSBA-2021/","title":"Data Science for Business Applications 2021","tags":[],"description":"","content":"Data Science for Business Applications 2021 CBS - Digi Welcome to the \u0026ldquo;Data Science for Business Analytics\u0026rdquo; page. Throughout this course, you will aquire skills, knowledge, and capabilities to navigate and actively participate in the application of data science, machine learning, and artificial intelligence techniques in business. We hope you are excited.\nNote that this page rather than Canvas will represent the central hub for teaching material. At DSBA we believe in the power of open science and open education, and consequently we make all our material available outside password protected university systems.\nThe corresponding canvas course page can be found here, and will not be updated for other things than providing the live-lecture calendar.\n"},{"uri":"https://sds-aau.github.io/DSBA-2021/tags/","title":"Tags","tags":[],"description":"","content":""}]